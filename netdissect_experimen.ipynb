{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYZOXnAWQippxT/oPiCY+X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thyungkim/NetDissect-Improve-Accuracy/blob/main/netdissect_experimen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Network Dissection (for classifiers)\n",
        "In this notebook, we will examine internal layer representations for a classifier trained to recognize scene categories.\n",
        "\n",
        "Setup matplotlib, torch, and numpy for a high-resolution browser.\n",
        "\n"
      ],
      "metadata": {
        "id": "dJKZYQScJ6WK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "msdUmV_bJTXa"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from importlib import reload\n",
        "import IPython\n",
        "mpl.rcParams['lines.linewidth'] = 0.25\n",
        "mpl.rcParams['axes.spines.top'] = False\n",
        "mpl.rcParams['axes.spines.right'] = False\n",
        "mpl.rcParams['axes.linewidth'] = 0.25"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up experiment directory and settings\n",
        "\n"
      ],
      "metadata": {
        "id": "-2gF_BcTJ_SU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, argparse, os, shutil, inspect, json, numpy, math\n",
        "from easydict import EasyDict\n",
        "import dissect_experiment as experiment\n",
        "# choices are alexnet, vgg16, or resnet152.\n",
        "args = EasyDict(model='vgg16', dataset='places', seg='netpqc', layer='conv5_3', quantile=0.01)\n",
        "resdir = 'results/%s-%s-%s-%s-%s' % (args.model, args.dataset, args.seg, args.layer, int(args.quantile * 1000))\n",
        "def resfile(f):\n",
        "    return os.path.join(resdir, f)"
      ],
      "metadata": {
        "id": "kT8AvuVQJvzd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load classifier model and dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "gz2cbIcHKBax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = experiment.load_model(args)\n",
        "layername = experiment.instrumented_layername(args)\n",
        "model.retain_layer(layername)\n",
        "dataset = experiment.load_dataset(args)\n",
        "upfn = experiment.make_upfn(args, dataset, model, layername)\n",
        "sample_size = len(dataset)\n",
        "percent_level = 1.0 - args.quantile\n",
        "\n",
        "print('Inspecting layer %s of model %s on %s' % (layername, args.model, args.dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mZxS_slJxV7",
        "outputId": "265ad62b-bd2f-48cf-a980-44f47719ea2f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "upsampling from data_shape (14, 14)\n",
            "Inspecting layer features.conv5_3 of model vgg16 on places\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "wf0jMHpVJyxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eed83e2-9a42-4f4f-fa6a-67affdfb3d4b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InstrumentedModel(\n",
              "  (model): VGG(\n",
              "    (features): Sequential(\n",
              "      (conv1_1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu1_1): ReLU(inplace=True)\n",
              "      (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu1_2): ReLU(inplace=True)\n",
              "      (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu2_1): ReLU(inplace=True)\n",
              "      (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu2_2): ReLU(inplace=True)\n",
              "      (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu3_1): ReLU(inplace=True)\n",
              "      (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu3_2): ReLU(inplace=True)\n",
              "      (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu3_3): ReLU(inplace=True)\n",
              "      (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu4_1): ReLU(inplace=True)\n",
              "      (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu4_2): ReLU(inplace=True)\n",
              "      (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu4_3): ReLU(inplace=True)\n",
              "      (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu5_1): ReLU(inplace=True)\n",
              "      (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu5_2): ReLU(inplace=True)\n",
              "      (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (relu5_3): ReLU(inplace=True)\n",
              "      (pool5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "    (classifier): Sequential(\n",
              "      (fc6): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "      (relu6): ReLU(inplace=True)\n",
              "      (drop6): Dropout(p=0.5, inplace=False)\n",
              "      (fc7): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "      (relu7): ReLU(inplace=True)\n",
              "      (drop7): Dropout(p=0.5, inplace=False)\n",
              "      (fc8a): Linear(in_features=4096, out_features=365, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load segmenter, segment labels, classifier labels\n",
        "\n"
      ],
      "metadata": {
        "id": "1sMJ3gjFKDB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Classifier labels\n",
        "from urllib.request import urlopen\n",
        "import renormalize\n",
        "\n",
        "# synset_url = 'http://gandissect.csail.mit.edu/models/categories_places365.txt'\n",
        "# classlabels = [r.split(' ')[0][3:] for r in urlopen(synset_url).read().decode('utf-8').split('\\n')]\n",
        "classlabels = dataset.classes\n",
        "segmodel, seglabels, segcatlabels = experiment.setting.load_segmenter(args.seg)\n",
        "renorm = renormalize.renormalizer(dataset, target='zc')"
      ],
      "metadata": {
        "id": "YdH11GbQJzz9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "27964e79-e497-4bf5-e751-652430179e65"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://dissect.csail.mit.edu/models/segmodel/upp-resnet50-upernet/decoder_epoch_40.pth\n",
            "Downloading https://dissect.csail.mit.edu/models/segmodel/upp-resnet50-upernet/encoder_epoch_40.pth\n",
            "Downloading https://dissect.csail.mit.edu/models/segmodel/upp-resnet50-upernet/labels.json\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-25c7ecc54d00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# classlabels = [r.split(' ')[0][3:] for r in urlopen(synset_url).read().decode('utf-8').split('\\n')]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclasslabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msegmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseglabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegcatlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_segmenter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mrenorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenormalize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenormalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'zc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/setting.py\u001b[0m in \u001b[0;36mload_segmenter\u001b[0;34m(segmenter_name)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0msegmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     segmodels.append(segmenter.UnifiedParsingSegmenter(segsizes=[256],\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mall_parts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_parts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             segdiv=('quad' if quad_seg else None)))\n",
            "\u001b[0;32m/content/segmenter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, segsizes, segdiv, all_parts)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mensure_segmenter_downloaded\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/segmodel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'upp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         segmodel = load_unified_parsing_segmentation_model(\n\u001b[0m\u001b[1;32m    146\u001b[0m             segarch, segvocab, epoch)\n\u001b[1;32m    147\u001b[0m         \u001b[0msegmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/segmenter.py\u001b[0m in \u001b[0;36mload_unified_parsing_segmentation_model\u001b[0;34m(segmodel_arch, segvocab, epoch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0mfc_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         weights=os.path.join(segmodel_dir, 'encoder_epoch_%d.pth' % epoch))\n\u001b[0;32m--> 582\u001b[0;31m     seg_decoder = segbuilder.build_decoder(\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0march\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msegmodel_arch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mfc_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_softmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/upseg_models.py\u001b[0m in \u001b[0;36mbuild_decoder\u001b[0;34m(self, nr_classes, arch, fc_dim, weights, use_softmax)\u001b[0m\n\u001b[1;32m    195\u001b[0m                 fpn_dim=256)\n\u001b[1;32m    196\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0march\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'upernet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             net_decoder = UPerNet(\n\u001b[0m\u001b[1;32m    198\u001b[0m                 \u001b[0mnr_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnr_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0mfc_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfc_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/upseg_models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nr_classes, fc_dim, use_softmax, pool_scales, fpn_inplanes, fpn_dim)\u001b[0m\n\u001b[1;32m    255\u001b[0m                  fpn_inplanes=(256,512,1024,2048), fpn_dim=256):\n\u001b[1;32m    256\u001b[0m         \u001b[0;31m# Lazy import so that compilation isn't needed if not being used.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mprroi_pool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrRoIPool2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUPerNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_softmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_softmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/prroi_pool.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprroi_pool2d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'PrRoIPool2D'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpp_extension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mload_extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mroot_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'src'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     _prroi_pooling = load_extension(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;34m'_prroi_pooling'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mpjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prroi_pooling_gpu.c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'prroi_pooling_gpu_impl.cu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         ...     verbose=True)\n\u001b[1;32m   1283\u001b[0m     '''\n\u001b[0;32m-> 1284\u001b[0;31m     return _jit_compile(\n\u001b[0m\u001b[1;32m   1285\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py\u001b[0m in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1465\u001b[0m     \u001b[0mwith_cudnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cudnn'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mextra_ldflags\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m     \u001b[0mold_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJIT_EXTENSION_VERSIONER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m     version = JIT_EXTENSION_VERSIONER.bump_version_if_changed(\n\u001b[0m\u001b[1;32m   1468\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m         \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/_cpp_extension_versioner.py\u001b[0m in \u001b[0;36mbump_version_if_changed\u001b[0;34m(self, name, source_files, build_arguments, build_directory, with_cuda, is_python_module, is_standalone)\u001b[0m\n\u001b[1;32m     43\u001b[0m                                 is_standalone):\n\u001b[1;32m     44\u001b[0m         \u001b[0mhash_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mhash_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_source_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mhash_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhash_build_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_arguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mhash_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/_cpp_extension_versioner.py\u001b[0m in \u001b[0;36mhash_source_files\u001b[0;34m(hash_value, source_files)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhash_source_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mhash_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/src/prroi_pooling_gpu.c'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test classifier on some images"
      ],
      "metadata": {
        "id": "7an05ncxKFSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import renormalize\n",
        "\n",
        "indices = [200, 755, 709, 423, 60, 100, 110, 120]\n",
        "batch = torch.cat([dataset[i][0][None,...] for i in indices])\n",
        "truth = [classlabels[dataset[i][1]] for i in indices]\n",
        "preds = model(batch.cuda()).max(1)[1]\n",
        "imgs = [renormalize.as_image(t, source=dataset) for t in batch]\n",
        "prednames = [classlabels[p.item()] for p in preds]\n",
        "show([[img, 'pred: ' + pred, 'true: ' + gt] for img, pred, gt in zip(imgs, prednames, truth)])"
      ],
      "metadata": {
        "id": "wtGLpqnmJ1A9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "segment single image, and visualize the labels\n",
        "\n"
      ],
      "metadata": {
        "id": "XfAfOrD_KJfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imgviz\n",
        "\n",
        "iv = imgviz.ImageVisualizer(120, source=dataset)\n",
        "seg = segmodel.segment_batch(renorm(batch).cuda(), downsample=4)\n",
        "\n",
        "show([(iv.image(batch[i]), iv.segmentation(seg[i,0]),\n",
        "            iv.segment_key(seg[i,-1], segmodel))\n",
        "            for i in range(len(seg))])"
      ],
      "metadata": {
        "id": "1D2BMHupKL2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualize activations for single layer of single image\n",
        "\n"
      ],
      "metadata": {
        "id": "Wr_gniNrKN32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import imgviz\n",
        "\n",
        "acts = model.retained_layer(layername).cpu()\n",
        "ivsmall = imgviz.ImageVisualizer((100, 100), source=dataset)\n",
        "display(show.blocks(\n",
        "    [[[ivsmall.masked_image(batch[0], acts, (0, u), percent_level=0.99)],\n",
        "      [ivsmall.heatmap(acts, (0, u), mode='nearest')]] for u in range(min(acts.shape[1], 12))]\n",
        "))\n",
        "\n",
        "num_units = acts.shape[1]"
      ],
      "metadata": {
        "id": "JDLsq41JKO8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Collect quantile statistics\n",
        "First, unconditional quantiles over the activations. We will upsample them to 56x56 to match with segmentations later."
      ],
      "metadata": {
        "id": "ed7IrdsvKQjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pbar\n",
        "import tally\n",
        "pbar.descnext('rq')\n",
        "def compute_samples(batch, *args):\n",
        "    image_batch = batch.cuda()\n",
        "    _ = model(image_batch)\n",
        "    acts = model.retained_layer(layername)\n",
        "    hacts = upfn(acts)\n",
        "    return hacts.permute(0, 2, 3, 1).contiguous().view(-1, acts.shape[1])\n",
        "rq = tally.tally_quantile(compute_samples, dataset,\n",
        "                          sample_size=sample_size,\n",
        "                          r=8192,\n",
        "                          num_workers=100,\n",
        "                          pin_memory=True,\n",
        "                          cachefile=resfile('rq.npz'))"
      ],
      "metadata": {
        "id": "Nx51aC63KTid",
        "outputId": "a0d8d94d-ed97-4819-f685-da48276c8399",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 100 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Visualize Units\n",
        "Collect topk stats first."
      ],
      "metadata": {
        "id": "T0IP6khBKWPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pbar.descnext('topk')\n",
        "def compute_image_max(batch, *args):\n",
        "    image_batch = batch.cuda()\n",
        "    _ = model(image_batch)\n",
        "    acts = model.retained_layer(layername)\n",
        "    acts = acts.view(acts.shape[0], acts.shape[1], -1)\n",
        "    acts = acts.max(2)[0]\n",
        "    return acts\n",
        "topk = tally.tally_topk(compute_image_max, dataset, sample_size=sample_size,\n",
        "        batch_size=50, num_workers=30, pin_memory=True,\n",
        "        cachefile=resfile('topk.npz'))"
      ],
      "metadata": {
        "id": "FB8zQeFHKXV9",
        "outputId": "0cc05101-bb13-4260-c19f-fd320d1662c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 30 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "topk:   0%|          | 0/730 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# single image visualization\n",
        "print(topk.result()[1][10][6], dataset.images[topk.result()[1][10][6]])\n",
        "image_number = topk.result()[1][10][4].item()\n",
        "unit_number = 10\n",
        "iv = imgviz.ImageVisualizer((224, 224), source=dataset, quantiles=rq,\n",
        "        level=rq.quantiles(percent_level))\n",
        "batch = torch.cat([dataset[i][0][None,...] for i in [image_number]])\n",
        "truth = [classlabels[dataset[i][1]] for i in [image_number]]\n",
        "preds = model(batch.cuda()).max(1)[1]\n",
        "imgs = [renormalize.as_image(t, source=dataset) for t in batch]\n",
        "prednames = [classlabels[p.item()] for p in preds]\n",
        "acts = model.retained_layer(layername)\n",
        "show([[img, 'pred: ' + pred, 'true: ' + gt] for img, pred, gt in zip(imgs, prednames, truth)])\n",
        "show([[iv.masked_image(batch[0], acts, (0, unit_number))]])"
      ],
      "metadata": {
        "id": "qsrPxjBCKbLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we just need to run through and visualize the images.\n",
        "\n"
      ],
      "metadata": {
        "id": "h8SlGAI4Kc9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pbar.descnext('unit_images')\n",
        "\n",
        "iv = imgviz.ImageVisualizer((100, 100), source=dataset, quantiles=rq,\n",
        "        level=rq.quantiles(percent_level))\n",
        "def compute_acts(image_batch):\n",
        "    image_batch = image_batch.cuda()\n",
        "    _ = model(image_batch)\n",
        "    acts_batch = model.retained_layer(layername)\n",
        "    return acts_batch\n",
        "unit_images = iv.masked_images_for_topk(\n",
        "        compute_acts, dataset, topk, k=5, num_workers=30, pin_memory=True,\n",
        "        cachefile=resfile('top5images.npz'))"
      ],
      "metadata": {
        "id": "SMaV9j3kKeHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for u in [10, 20, 30, 40, 19, 190]:\n",
        "    print('unit %d' % u)\n",
        "    display(unit_images[u])"
      ],
      "metadata": {
        "id": "XccY19r3Kfg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Label Units\n",
        "Collect 99% quantile stats."
      ],
      "metadata": {
        "id": "v_M19pBeKggG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "level_at_99 = rq.quantiles(percent_level).cuda()[None,:,None,None]\n",
        "# Use the segmodel for segmentations.  With broden, we could use ground truth instead.\n",
        "def compute_conditional_indicator(batch, *args):\n",
        "    image_batch = batch.cuda()\n",
        "    seg = segmodel.segment_batch(renorm(image_batch), downsample=4)\n",
        "    _ = model(image_batch)\n",
        "    acts = model.retained_layer(layername)\n",
        "    hacts = upfn(acts)\n",
        "    iacts = (hacts > level_at_99).float() # indicator\n",
        "    return tally.conditional_samples(iacts, seg)\n",
        "pbar.descnext('condi99')\n",
        "condi99 = tally.tally_conditional_mean(compute_conditional_indicator,\n",
        "        dataset, sample_size=sample_size,\n",
        "        num_workers=3, pin_memory=True,\n",
        "        cachefile=resfile('condi99.npz'))"
      ],
      "metadata": {
        "id": "XFkYoyyOKmjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "iou_99 = tally.iou_from_conditional_indicator_mean(condi99)\n",
        "unit_label_99 = [\n",
        "        (concept.item(), seglabels[concept], segcatlabels[concept], bestiou.item())\n",
        "        for (bestiou, concept) in zip(*iou_99.max(0))]\n",
        "label_list = [labelcat for concept, label, labelcat, iou in unit_label_99 if iou > 0.04]\n",
        "display(IPython.display.SVG(experiment.graph_conceptcatlist(label_list)))\n",
        "len(label_list)"
      ],
      "metadata": {
        "id": "8ELImR5tKoEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show a few units with their labels\n",
        "\n"
      ],
      "metadata": {
        "id": "GbJyQR1SKobY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for u in [10, 20, 30, 40]:\n",
        "    print('unit %d, label %s, iou %.3f' % (u, unit_label_99[u][1], unit_label_99[u][3]))\n",
        "    display(unit_images[u])"
      ],
      "metadata": {
        "id": "8f9Dv4SEKpvH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}