{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO97IuIVD7BlFnywmKC0idz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thyungkim/NetDissect-Improve-Accuracy/blob/main/dissect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eabkcfim8yIS"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from importlib import reload\n",
        "import IPython\n",
        "mpl.rcParams['lines.linewidth'] = 0.25\n",
        "mpl.rcParams['axes.spines.top'] = False\n",
        "mpl.rcParams['axes.spines.right'] = False\n",
        "mpl.rcParams['axes.linewidth'] = 0.25"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, argparse, os, shutil, inspect, json, numpy, math\n",
        "import netdissect\n",
        "from netdissect.easydict import EasyDict\n",
        "from netdissect import pbar, nethook, renormalize, parallelfolder, pidfile\n",
        "from netdissect import upsample, tally, imgviz, imgsave, bargraph, show\n",
        "from experiment import dissect_experiment as experiment\n",
        "\n",
        "# choices are alexnet, vgg16, or resnet152.\n",
        "args = EasyDict(model='vgg16', dataset='places', seg='netpqc', layer='conv5_3', quantile=0.01)\n",
        "resdir = 'results/%s-%s-%s-%s-%s' % (args.model, args.dataset, args.seg, args.layer, int(args.quantile * 1000))\n",
        "def resfile(f):\n",
        "    return os.path.join(resdir, f)"
      ],
      "metadata": {
        "id": "oG6r-Rxz805r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = experiment.load_model(args)\n",
        "layername = experiment.instrumented_layername(args)\n",
        "model.retain_layer(layername)\n",
        "dataset = experiment.load_dataset(args)\n",
        "upfn = experiment.make_upfn(args, dataset, model, layername)\n",
        "sample_size = len(dataset)\n",
        "percent_level = 1.0 - args.quantile\n",
        "\n",
        "print('Inspecting layer %s of model %s on %s' % (layername, args.model, args.dataset))"
      ],
      "metadata": {
        "id": "F9AgWTNT81BT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classifier labels\n",
        "from urllib.request import urlopen\n",
        "from netdissect import renormalize\n",
        "\n",
        "# synset_url = 'http://gandissect.csail.mit.edu/models/categories_places365.txt'\n",
        "# classlabels = [r.split(' ')[0][3:] for r in urlopen(synset_url).read().decode('utf-8').split('\\n')]\n",
        "classlabels = dataset.classes\n",
        "segmodel, seglabels, segcatlabels = experiment.setting.load_segmenter(args.seg)\n",
        "renorm = renormalize.renormalizer(dataset, target='zc')"
      ],
      "metadata": {
        "id": "HWgHQPix81Dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from netdissect import renormalize\n",
        "\n",
        "indices = [200, 755, 709, 423, 60, 100, 110, 120]\n",
        "batch = torch.cat([dataset[i][0][None,...] for i in indices])\n",
        "truth = [classlabels[dataset[i][1]] for i in indices]\n",
        "preds = model(batch.cuda()).max(1)[1]\n",
        "imgs = [renormalize.as_image(t, source=dataset) for t in batch]\n",
        "prednames = [classlabels[p.item()] for p in preds]\n",
        "show([[img, 'pred: ' + pred, 'true: ' + gt] for img, pred, gt in zip(imgs, prednames, truth)])"
      ],
      "metadata": {
        "id": "JLYHtZFS81Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from netdissect import imgviz\n",
        "\n",
        "iv = imgviz.ImageVisualizer(120, source=dataset)\n",
        "seg = segmodel.segment_batch(renorm(batch).cuda(), downsample=4)\n",
        "\n",
        "show([(iv.image(batch[i]), iv.segmentation(seg[i,0]),\n",
        "            iv.segment_key(seg[i,-1], segmodel))\n",
        "            for i in range(len(seg))])"
      ],
      "metadata": {
        "id": "lylvNes181JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from netdissect import imgviz\n",
        "\n",
        "acts = model.retained_layer(layername).cpu()\n",
        "ivsmall = imgviz.ImageVisualizer((100, 100), source=dataset)\n",
        "display(show.blocks(\n",
        "    [[[ivsmall.masked_image(batch[0], acts, (0, u), percent_level=0.99)],\n",
        "      [ivsmall.heatmap(acts, (0, u), mode='nearest')]] for u in range(min(acts.shape[1], 12))]\n",
        "))\n",
        "\n",
        "num_units = acts.shape[1]"
      ],
      "metadata": {
        "id": "nuAvsa5o81L4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collect quantile statistics"
      ],
      "metadata": {
        "id": "nacEP6id8_hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pbar.descnext('rq')\n",
        "def compute_samples(batch, *args):\n",
        "    image_batch = batch.cuda()\n",
        "    _ = model(image_batch)\n",
        "    acts = model.retained_layer(layername)\n",
        "    hacts = upfn(acts)\n",
        "    return hacts.permute(0, 2, 3, 1).contiguous().view(-1, acts.shape[1])\n",
        "rq = tally.tally_quantile(compute_samples, dataset,\n",
        "                          sample_size=sample_size,\n",
        "                          r=8192,\n",
        "                          num_workers=100,\n",
        "                          pin_memory=True,\n",
        "                          cachefile=resfile('rq.npz'))"
      ],
      "metadata": {
        "id": "u5NkeY-f88zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize Units"
      ],
      "metadata": {
        "id": "zPN1vX1l8_Dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pbar.descnext('topk')\n",
        "def compute_image_max(batch, *args):\n",
        "    image_batch = batch.cuda()\n",
        "    _ = model(image_batch)\n",
        "    acts = model.retained_layer(layername)\n",
        "    acts = acts.view(acts.shape[0], acts.shape[1], -1)\n",
        "    acts = acts.max(2)[0]\n",
        "    return acts\n",
        "topk = tally.tally_topk(compute_image_max, dataset, sample_size=sample_size,\n",
        "        batch_size=50, num_workers=30, pin_memory=True,\n",
        "        cachefile=resfile('topk.npz'))"
      ],
      "metadata": {
        "id": "yln-xwTR881e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# single image visualization\n",
        "print(topk.result()[1][10][6], dataset.images[topk.result()[1][10][6]])\n",
        "image_number = topk.result()[1][10][4].item()\n",
        "unit_number = 10\n",
        "iv = imgviz.ImageVisualizer((224, 224), source=dataset, quantiles=rq,\n",
        "        level=rq.quantiles(percent_level))\n",
        "batch = torch.cat([dataset[i][0][None,...] for i in [image_number]])\n",
        "truth = [classlabels[dataset[i][1]] for i in [image_number]]\n",
        "preds = model(batch.cuda()).max(1)[1]\n",
        "imgs = [renormalize.as_image(t, source=dataset) for t in batch]\n",
        "prednames = [classlabels[p.item()] for p in preds]\n",
        "acts = model.retained_layer(layername)\n",
        "show([[img, 'pred: ' + pred, 'true: ' + gt] for img, pred, gt in zip(imgs, prednames, truth)])\n",
        "show([[iv.masked_image(batch[0], acts, (0, unit_number))]])"
      ],
      "metadata": {
        "id": "cXe01cS-9Gdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pbar.descnext('unit_images')\n",
        "\n",
        "iv = imgviz.ImageVisualizer((100, 100), source=dataset, quantiles=rq,\n",
        "        level=rq.quantiles(percent_level))\n",
        "def compute_acts(image_batch):\n",
        "    image_batch = image_batch.cuda()\n",
        "    _ = model(image_batch)\n",
        "    acts_batch = model.retained_layer(layername)\n",
        "    return acts_batch\n",
        "unit_images = iv.masked_images_for_topk(\n",
        "        compute_acts, dataset, topk, k=5, num_workers=30, pin_memory=True,\n",
        "        cachefile=resfile('top5images.npz'))"
      ],
      "metadata": {
        "id": "S9269OKB9Gks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for u in [10, 20, 30, 40, 19, 190]:\n",
        "    print('unit %d' % u)\n",
        "    display(unit_images[u])"
      ],
      "metadata": {
        "id": "NZNddtxg9GnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Units\n"
      ],
      "metadata": {
        "id": "FQTLoXEp9LzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "level_at_99 = rq.quantiles(percent_level).cuda()[None,:,None,None]\n",
        "# Use the segmodel for segmentations.  With broden, we could use ground truth instead.\n",
        "def compute_conditional_indicator(batch, *args):\n",
        "    image_batch = batch.cuda()\n",
        "    seg = segmodel.segment_batch(renorm(image_batch), downsample=4)\n",
        "    _ = model(image_batch)\n",
        "    acts = model.retained_layer(layername)\n",
        "    hacts = upfn(acts)\n",
        "    iacts = (hacts > level_at_99).float() # indicator\n",
        "    return tally.conditional_samples(iacts, seg)\n",
        "pbar.descnext('condi99')\n",
        "condi99 = tally.tally_conditional_mean(compute_conditional_indicator,\n",
        "        dataset, sample_size=sample_size,\n",
        "        num_workers=3, pin_memory=True,\n",
        "        cachefile=resfile('condi99.npz'))"
      ],
      "metadata": {
        "id": "ElXeQKJo9Gph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "iou_99 = tally.iou_from_conditional_indicator_mean(condi99)\n",
        "unit_label_99 = [\n",
        "        (concept.item(), seglabels[concept], segcatlabels[concept], bestiou.item())\n",
        "        for (bestiou, concept) in zip(*iou_99.max(0))]\n",
        "label_list = [labelcat for concept, label, labelcat, iou in unit_label_99 if iou > 0.04]\n",
        "display(IPython.display.SVG(experiment.graph_conceptcatlist(label_list)))\n",
        "len(label_list)"
      ],
      "metadata": {
        "id": "c4sbYbQQ9R5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for u in [10, 20, 30, 40]:\n",
        "    print('unit %d, label %s, iou %.3f' % (u, unit_label_99[u][1], unit_label_99[u][3]))\n",
        "    display(unit_images[u])"
      ],
      "metadata": {
        "id": "OTnkLh7v9TEB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}